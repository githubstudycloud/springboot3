spring:
  application:
    name: spring-ai-core-demo
  
  ai:
    # OpenAI Configuration
    openai:
      api-key: ${OPENAI_API_KEY:your-api-key-here}
      chat:
        options:
          model: gpt-4o
          temperature: 0.7
    
    # Anthropic Configuration  
    anthropic:
      api-key: ${ANTHROPIC_API_KEY:your-api-key-here}
      chat:
        options:
          model: claude-3-5-sonnet-20241022
          max-tokens: 1024
    
    # Azure OpenAI Configuration
    azure:
      openai:
        api-key: ${AZURE_OPENAI_API_KEY:your-api-key-here}
        endpoint: ${AZURE_OPENAI_ENDPOINT:your-endpoint-here}
        chat:
          options:
            deployment-name: ${AZURE_OPENAI_DEPLOYMENT_NAME:your-deployment-name}
    
    # Ollama Configuration (for local models)
    ollama:
      base-url: ${OLLAMA_BASE_URL:http://localhost:11434}
      chat:
        options:
          model: llama3.2
          temperature: 0.7

server:
  port: 8080

logging:
  level:
    com.example.springai: DEBUG
    org.springframework.ai: DEBUG
