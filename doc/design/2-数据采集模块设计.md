# 数据采集模块设计

## platform-collect (数据采集模块)

**设计目标**：
构建高性能、可扩展的数据采集框架，支持多种数据源连接和采集方式，实现数据从源系统到平台的高效、可靠传输。

**核心功能**：
1. 支持多种数据源连接：关系型数据库、NoSQL、消息队列、API、文件等
2. 批量与实时采集：支持批处理和流式处理两种模式
3. 增量采集：基于时间戳、日志等方式的增量数据提取
4. 采集任务管理：任务创建、配置、调度和监控
5. 数据转换与清洗：采集过程中的简单数据转换与清洗

**领域模型**：
1. 数据源聚合：DataSource(聚合根)、ConnectionConfig、ConnectionTest
2. 采集任务聚合：CollectTask(聚合根)、TaskConfig、TaskSchedule、TaskExecution
3. 采集过程聚合：CollectProcess(聚合根)、ProcessStep、ProcessMetrics
4. 数据结构聚合：DataStructure(聚合根)、Field、FieldMapping

## 子模块设计

### platform-collect-api

**职责**：
- 定义数据采集模块的接口和契约
- 提供跨模块调用的DTO和命令对象
- 定义事件类型和监听接口

**主要组件**：

1. **DTO对象**
```java
/**
 * 数据源DTO
 */
@Data
@Builder
public class DataSourceDTO {
    private String id;
    private String name;
    private String description;
    private DataSourceType type;
    private ConnectionConfigDTO connectionConfig;
    private String createdBy;
    private LocalDateTime createdAt;
    private String updatedBy;
    private LocalDateTime updatedAt;
}

/**
 * 采集任务DTO
 */
@Data
@Builder
public class CollectTaskDTO {
    private String id;
    private String name;
    private String description;
    private String sourceId;
    private String targetId;
    private TaskConfigDTO taskConfig;
    private TaskScheduleDTO taskSchedule;
    private TaskStatus status;
    private String createdBy;
    private LocalDateTime createdAt;
    private String updatedBy;
    private LocalDateTime updatedAt;
}
```

2. **命令对象**
```java
/**
 * 创建数据源命令
 */
@Data
@Builder
public class CreateDataSourceCommand {
    private String name;
    private String description;
    private DataSourceType type;
    private ConnectionConfigDTO connectionConfig;
    private String createdBy;
}

/**
 * 创建采集任务命令
 */
@Data
@Builder
public class CreateCollectTaskCommand {
    private String name;
    private String description;
    private String sourceId;
    private String targetId;
    private TaskConfigDTO taskConfig;
    private TaskScheduleDTO taskSchedule;
    private String createdBy;
}
```

3. **事件定义**
```java
/**
 * 数据源创建事件
 */
@Data
public class DataSourceCreatedEvent implements DomainEvent {
    private final String dataSourceId;
    private final String dataSourceName;
    private final String dataSourceType;
    private final LocalDateTime occurredOn;
    
    public DataSourceCreatedEvent(String dataSourceId, String dataSourceName, String dataSourceType) {
        this.dataSourceId = dataSourceId;
        this.dataSourceName = dataSourceName;
        this.dataSourceType = dataSourceType;
        this.occurredOn = LocalDateTime.now();
    }
}

/**
 * 采集任务创建事件
 */
@Data
public class CollectTaskCreatedEvent implements DomainEvent {
    private final String taskId;
    private final String taskName;
    private final String sourceId;
    private final String targetId;
    private final LocalDateTime occurredOn;
    
    public CollectTaskCreatedEvent(String taskId, String taskName, String sourceId, String targetId) {
        this.taskId = taskId;
        this.taskName = taskName;
        this.sourceId = sourceId;
        this.targetId = targetId;
        this.occurredOn = LocalDateTime.now();
    }
}
```

4. **服务接口**
```java
/**
 * 数据源服务接口
 */
public interface DataSourceService {
    /**
     * 创建数据源
     * @param command 创建数据源命令
     * @return 数据源DTO
     */
    DataSourceDTO createDataSource(CreateDataSourceCommand command);
    
    /**
     * 测试数据源连接
     * @param dataSourceId 数据源ID
     * @return 连接测试结果
     */
    ConnectionTestResultDTO testConnection(String dataSourceId);
    
    /**
     * 获取数据源元数据
     * @param dataSourceId 数据源ID
     * @return 元数据信息
     */
    MetadataResultDTO getMetadata(String dataSourceId);
}

/**
 * 采集任务服务接口
 */
public interface CollectTaskService {
    /**
     * 创建采集任务
     * @param command 创建采集任务命令
     * @return 采集任务DTO
     */
    CollectTaskDTO createCollectTask(CreateCollectTaskCommand command);
    
    /**
     * 启动采集任务
     * @param taskId 任务ID
     * @return 任务执行DTO
     */
    TaskExecutionDTO startTask(String taskId);
    
    /**
     * 停止采集任务
     * @param taskId 任务ID
     */
    void stopTask(String taskId);
    
    /**
     * 获取任务执行状态
     * @param executionId 执行ID
     * @return 执行状态
     */
    TaskExecutionDTO getExecutionStatus(String executionId);
}
```

### platform-collect-core

**职责**：
- 实现数据采集的核心框架
- 提供通用的采集引擎和流程控制
- 实现配置管理和任务调度

**领域模型实现**：

```java
/**
 * 数据源领域模型
 */
@Entity
@Table(name = "col_data_source")
public class DataSource implements AggregateRoot<DataSourceId> {
    @EmbeddedId
    private DataSourceId id;
    
    @Column(name = "name", nullable = false)
    private String name;
    
    @Column(name = "type", nullable = false)
    @Enumerated(EnumType.STRING)
    private DataSourceType type;
    
    @Column(name = "description")
    private String description;
    
    @Embedded
    private ConnectionConfig connectionConfig;
    
    @Column(name = "created_at", nullable = false)
    private LocalDateTime createdAt;
    
    @Column(name = "updated_at", nullable = false)
    private LocalDateTime updatedAt;
    
    @Column(name = "created_by", nullable = false)
    private String createdBy;
    
    @Column(name = "updated_by", nullable = false)
    private String updatedBy;
    
    protected DataSource() {}
    
    public DataSource(DataSourceId id, String name, DataSourceType type, 
                     ConnectionConfig connectionConfig, String createdBy) {
        this.id = id;
        this.name = name;
        this.type = type;
        this.connectionConfig = connectionConfig;
        this.createdAt = LocalDateTime.now();
        this.updatedAt = this.createdAt;
        this.createdBy = createdBy;
        this.updatedBy = createdBy;
    }
    
    public ConnectionTestResult testConnection(ConnectionTester tester) {
        return tester.test(this.type, this.connectionConfig);
    }
    
    public void updateConnectionConfig(ConnectionConfig connectionConfig, String updatedBy) {
        this.connectionConfig = connectionConfig;
        this.updatedAt = LocalDateTime.now();
        this.updatedBy = updatedBy;
    }
    
    public void updateBasicInfo(String name, String description, String updatedBy) {
        this.name = name;
        this.description = description;
        this.updatedAt = LocalDateTime.now();
        this.updatedBy = updatedBy;
    }
    
    @Override
    public DataSourceId getId() {
        return id;
    }
    
    // Getter methods
}

/**
 * 连接配置值对象
 */
@Embeddable
public class ConnectionConfig implements ValueObject {
    @Column(name = "connection_url")
    private String connectionUrl;
    
    @Column(name = "username")
    private String username;
    
    @Column(name = "password")
    private String password; // 应该加密存储
    
    @Column(name = "driver_class")
    private String driverClass;
    
    @Column(name = "connection_properties", columnDefinition = "TEXT")
    private String connectionProperties; // JSON格式存储额外属性
    
    @Column(name = "max_connections")
    private Integer maxConnections;
    
    @Column(name = "timeout_seconds")
    private Integer timeoutSeconds;
    
    protected ConnectionConfig() {}
    
    private ConnectionConfig(Builder builder) {
        this.connectionUrl = builder.connectionUrl;
        this.username = builder.username;
        this.password = builder.password;
        this.driverClass = builder.driverClass;
        this.connectionProperties = builder.connectionProperties;
        this.maxConnections = builder.maxConnections;
        this.timeoutSeconds = builder.timeoutSeconds;
    }
    
    public static class Builder {
        private String connectionUrl;
        private String username;
        private String password;
        private String driverClass;
        private String connectionProperties;
        private Integer maxConnections = 10; // 默认值
        private Integer timeoutSeconds = 30; // 默认值
        
        public Builder connectionUrl(String connectionUrl) {
            this.connectionUrl = connectionUrl;
            return this;
        }
        
        public Builder username(String username) {
            this.username = username;
            return this;
        }
        
        public Builder password(String password) {
            this.password = password;
            return this;
        }
        
        public Builder driverClass(String driverClass) {
            this.driverClass = driverClass;
            return this;
        }
        
        public Builder connectionProperties(String connectionProperties) {
            this.connectionProperties = connectionProperties;
            return this;
        }
        
        public Builder maxConnections(Integer maxConnections) {
            this.maxConnections = maxConnections;
            return this;
        }
        
        public Builder timeoutSeconds(Integer timeoutSeconds) {
            this.timeoutSeconds = timeoutSeconds;
            return this;
        }
        
        public ConnectionConfig build() {
            return new ConnectionConfig(this);
        }
    }
    
    // Getter methods
}

/**
 * 采集任务领域模型
 */
@Entity
@Table(name = "col_collect_task")
public class CollectTask implements AggregateRoot<CollectTaskId> {
    @EmbeddedId
    private CollectTaskId id;
    
    @Column(name = "name", nullable = false)
    private String name;
    
    @Column(name = "description")
    private String description;
    
    @Column(name = "source_id", nullable = false)
    private String sourceId;
    
    @Column(name = "target_id", nullable = false)
    private String targetId;
    
    @Embedded
    private TaskConfig taskConfig;
    
    @Embedded
    private TaskSchedule taskSchedule;
    
    @Column(name = "status", nullable = false)
    @Enumerated(EnumType.STRING)
    private TaskStatus status;
    
    @Column(name = "created_at", nullable = false)
    private LocalDateTime createdAt;
    
    @Column(name = "updated_at", nullable = false)
    private LocalDateTime updatedAt;
    
    @Column(name = "created_by", nullable = false)
    private String createdBy;
    
    @Column(name = "updated_by", nullable = false)
    private String updatedBy;
    
    @OneToMany(mappedBy = "taskId", cascade = CascadeType.ALL, orphanRemoval = true)
    private List<TaskExecution> executions = new ArrayList<>();
    
    protected CollectTask() {}
    
    public CollectTask(CollectTaskId id, String name, String sourceId, String targetId, 
                      TaskConfig taskConfig, TaskSchedule taskSchedule, String createdBy) {
        this.id = id;
        this.name = name;
        this.sourceId = sourceId;
        this.targetId = targetId;
        this.taskConfig = taskConfig;
        this.taskSchedule = taskSchedule;
        this.status = TaskStatus.INACTIVE;
        this.createdAt = LocalDateTime.now();
        this.updatedAt = this.createdAt;
        this.createdBy = createdBy;
        this.updatedBy = createdBy;
    }
    
    public void activate() {
        if (this.status == TaskStatus.INACTIVE) {
            this.status = TaskStatus.ACTIVE;
            this.updatedAt = LocalDateTime.now();
        }
    }
    
    public void deactivate() {
        if (this.status == TaskStatus.ACTIVE) {
            this.status = TaskStatus.INACTIVE;
            this.updatedAt = LocalDateTime.now();
        }
    }
    
    public TaskExecution startExecution(String executedBy) {
        if (this.status != TaskStatus.ACTIVE) {
            throw new TaskInactiveException("Cannot execute inactive task: " + this.id.getValue());
        }
        
        TaskExecution execution = new TaskExecution(
            TaskExecutionId.generate(),
            this.id,
            ExecutionStatus.RUNNING,
            executedBy
        );
        
        this.executions.add(execution);
        this.updatedAt = LocalDateTime.now();
        
        return execution;
    }
    
    public void completeExecution(TaskExecutionId executionId, ExecutionStatus status, 
                                 ExecutionResult result) {
        TaskExecution execution = findExecution(executionId);
        execution.complete(status, result);
        this.updatedAt = LocalDateTime.now();
    }
    
    private TaskExecution findExecution(TaskExecutionId executionId) {
        return this.executions.stream()
            .filter(e -> e.getId().equals(executionId))
            .findFirst()
            .orElseThrow(() -> new ExecutionNotFoundException(
                "Execution not found: " + executionId.getValue())
            );
    }
    
    @Override
    public CollectTaskId getId() {
        return id;
    }
    
    // Getter methods
}
```

**采集引擎设计**：

```java
/**
 * 采集引擎接口
 */
public interface CollectEngine {
    /**
     * 执行采集任务
     * @param task 采集任务
     * @param execution 任务执行
     * @return 执行结果
     */
    ExecutionResult execute(CollectTask task, TaskExecution execution);
    
    /**
     * 取消任务执行
     * @param executionId 执行ID
     */
    void cancel(TaskExecutionId executionId);
    
    /**
     * 获取执行状态
     * @param executionId 执行ID
     * @return 执行状态
     */
    ExecutionStatus getStatus(TaskExecutionId executionId);
}

/**
 * 批处理采集引擎实现
 */
@Component
public class BatchCollectEngine implements CollectEngine {
    private final DataSourceConnectorFactory connectorFactory;
    private final DataLoaderFactory loaderFactory;
    private final DataProcessorRegistry processorRegistry;
    private final ExecutionRepository executionRepository;
    private final Map<String, ExecutionContext> runningExecutions = new ConcurrentHashMap<>();
    
    @Override
    public ExecutionResult execute(CollectTask task, TaskExecution execution) {
        try {
            // 创建执行上下文
            ExecutionContext context = new ExecutionContext(
                execution.getId().getValue(),
                task.getId().getValue()
            );
            
            // 记录开始时间
            context.setStartTime(LocalDateTime.now());
            
            // 添加到运行中的执行
            runningExecutions.put(execution.getId().getValue(), context);
            
            // 获取数据源连接器
            DataSourceConnector connector = connectorFactory.getConnector(
                getDataSourceType(task.getSourceId())
            );
            
            // 获取数据加载器
            DataLoader loader = loaderFactory.getLoader(
                getDataSourceType(task.getTargetId())
            );
            
            // 构建查询
            DataQuery query = buildQuery(task.getTaskConfig());
            
            // 从源读取数据
            DataReadResult readResult = connector.read(
                getConnectionConfig(task.getSourceId()),
                query
            );
            
            // 更新上下文
            context.setTotalRecords(readResult.getTotalRecords());
            context.setStatus(ExecutionStatus.PROCESSING);
            
            // 处理数据
            List<DataRecord> processedRecords = processRecords(
                readResult.getRecords(),
                task.getTaskConfig()
            );
            
            // 更新上下文
            context.setProcessedRecords(processedRecords.size());
            context.setStatus(ExecutionStatus.LOADING);
            
            // 加载数据到目标
            DataLoadResult loadResult = loader.load(
                getConnectionConfig(task.getTargetId()),
                processedRecords,
                task.getTaskConfig()
            );
            
            // 更新上下文
            context.setLoadedRecords(loadResult.getLoadedRecords());
            context.setErrorRecords(loadResult.getErrorRecords());
            context.setEndTime(LocalDateTime.now());
            context.setStatus(ExecutionStatus.COMPLETED);
            
            // 构建执行结果
            ExecutionResult result = new ExecutionResult.Builder()
                .totalRecords(readResult.getTotalRecords())
                .processedRecords(processedRecords.size())
                .loadedRecords(loadResult.getLoadedRecords())
                .errorRecords(loadResult.getErrorRecords())
                .executionTimeMillis(
                    Duration.between(context.getStartTime(), context.getEndTime()).toMillis()
                )
                .build();
            
            // 从运行中的执行中移除
            runningExecutions.remove(execution.getId().getValue());
            
            return result;
            
        } catch (Exception e) {
            // 记录异常
            ExecutionContext context = runningExecutions.get(execution.getId().getValue());
            if (context != null) {
                context.setStatus(ExecutionStatus.FAILED);
                context.setEndTime(LocalDateTime.now());
                context.setErrorMessage(e.getMessage());
                runningExecutions.remove(execution.getId().getValue());
            }
            
            // 构建失败结果
            return new ExecutionResult.Builder()
                .success(false)
                .errorMessage(e.getMessage())
                .build();
        }
    }
    
    @Override
    public void cancel(TaskExecutionId executionId) {
        ExecutionContext context = runningExecutions.get(executionId.getValue());
        if (context != null) {
            context.setStatus(ExecutionStatus.CANCELLED);
            context.setEndTime(LocalDateTime.now());
            runningExecutions.remove(executionId.getValue());
        }
    }
    
    @Override
    public ExecutionStatus getStatus(TaskExecutionId executionId) {
        ExecutionContext context = runningExecutions.get(executionId.getValue());
        if (context != null) {
            return context.getStatus();
        }
        
        // 从数据库查询已完成的执行
        return executionRepository.findById(executionId)
            .map(TaskExecution::getStatus)
            .orElse(ExecutionStatus.UNKNOWN);
    }
    
    // 辅助方法
    private DataSourceType getDataSourceType(String dataSourceId) {
        // 从数据库或缓存中获取数据源类型
        return dataSourceRepository.findTypeById(dataSourceId);
    }
    
    private ConnectionConfig getConnectionConfig(String dataSourceId) {
        // 从数据库或缓存中获取连接配置
        return dataSourceRepository.findConnectionConfigById(dataSourceId);
    }
    
    private DataQuery buildQuery(TaskConfig taskConfig) {
        // 根据任务配置构建查询
        return new DataQuery.Builder()
            .sql(taskConfig.getSql())
            .collection(taskConfig.getCollection())
            .filters(taskConfig.getFilters())
            .batchSize(taskConfig.getBatchSize())
            .incremental(taskConfig.isIncremental())
            .lastValue(taskConfig.getLastValue())
            .build();
    }
    
    private List<DataRecord> processRecords(List<DataRecord> records, TaskConfig taskConfig) {
        // 应用数据处理器
        List<DataRecord> processedRecords = new ArrayList<>(records);
        
        for (String processorName : taskConfig.getProcessors()) {
            DataProcessor processor = processorRegistry.getProcessor(processorName);
            processedRecords = processor.process(processedRecords, taskConfig.getProcessorParams());
        }
        
        return processedRecords;
    }
}
```

**应用服务实现**：

```java
/**
 * 数据源应用服务实现
 */
@Service
@Transactional
public class DataSourceApplicationService implements DataSourceService {
    private final DataSourceRepository dataSourceRepository;
    private final DataSourceConnectorFactory connectorFactory;
    private final DomainEventPublisher eventPublisher;
    
    @Override
    public DataSourceDTO createDataSource(CreateDataSourceCommand command) {
        // 验证数据源名称唯一性
        if (dataSourceRepository.existsByName(command.getName())) {
            throw new DataSourceNameDuplicateException(command.getName());
        }
        
        // 构建连接配置
        ConnectionConfig connectionConfig = ConnectionConfig.builder()
            .connectionUrl(command.getConnectionConfig().getConnectionUrl())
            .username(command.getConnectionConfig().getUsername())
            .password(command.getConnectionConfig().getPassword())
            .driverClass(command.getConnectionConfig().getDriverClass())
            .connectionProperties(command.getConnectionConfig().getConnectionProperties())
            .maxConnections(command.getConnectionConfig().getMaxConnections())
            .timeoutSeconds(command.getConnectionConfig().getTimeoutSeconds())
            .build();
        
        // 创建数据源
        DataSource dataSource = new DataSource(
            DataSourceId.generate(),
            command.getName(),
            command.getType(),
            connectionConfig,
            command.getCreatedBy()
        );
        
        dataSource.setDescription(command.getDescription());
        
        // 保存数据源
        dataSourceRepository.save(dataSource);
        
        // 发布领域事件
        eventPublisher.publish(new DataSourceCreatedEvent(
            dataSource.getId().getValue(),
            dataSource.getName(),
            dataSource.getType().name()
        ));
        
        // 返回DTO
        return DataSourceDTOAssembler.toDTO(dataSource);
    }
    
    @Override
    public ConnectionTestResultDTO testConnection(String dataSourceId) {
        // 获取数据源
        DataSource dataSource = findDataSourceById(dataSourceId);
        
        // 获取连接器
        DataSourceConnector connector = connectorFactory.getConnector(dataSource.getType());
        
        // 测试连接
        ConnectionTestResult result = dataSource.testConnection(
            new ConnectionTester(connector)
        );
        
        // 返回DTO
        return ConnectionTestResultDTOAssembler.toDTO(result);
    }
    
    @Override
    public MetadataResultDTO getMetadata(String dataSourceId) {
        // 获取数据源
        DataSource dataSource = findDataSourceById(dataSourceId);
        
        // 获取连接器
        DataSourceConnector connector = connectorFactory.getConnector(dataSource.getType());
        
        // 获取元数据
        MetadataResult result = connector.getMetadata(dataSource.getConnectionConfig());
        
        // 返回DTO
        return MetadataResultDTOAssembler.toDTO(result);
    }
    
    private DataSource findDataSourceById(String dataSourceId) {
        return dataSourceRepository.findById(DataSourceId.of(dataSourceId))
            .orElseThrow(() -> new DataSourceNotFoundException(dataSourceId));
    }
}

/**
 * 采集任务应用服务实现
 */
@Service
@Transactional
public class CollectTaskApplicationService implements CollectTaskService {
    private final CollectTaskRepository taskRepository;
    private final DataSourceRepository dataSourceRepository;
    private final TaskExecutionRepository executionRepository;
    private final CollectEngine collectEngine;
    private final DomainEventPublisher eventPublisher;
    
    @Override
    public CollectTaskDTO createCollectTask(CreateCollectTaskCommand command) {
        // 验证数据源存在
        validateDataSource(command.getSourceId());
        validateDataSource(command.getTargetId());
        
        // 验证任务名称唯一性
        if (taskRepository.existsByName(command.getName())) {
            throw new TaskNameDuplicateException(command.getName());
        }
        
        // 构建任务配置
        TaskConfig taskConfig = TaskConfig.fromDto(command.getTaskConfig());
        
        // 构建任务调度
        TaskSchedule taskSchedule = TaskSchedule.fromDto(command.getTaskSchedule());
        
        // 创建采集任务
        CollectTask task = new CollectTask(
            CollectTaskId.generate(),
            command.getName(),
            command.getSourceId(),
            command.getTargetId(),
            taskConfig,
            taskSchedule,
            command.getCreatedBy()
        );
        
        task.setDescription(command.getDescription());
        
        // 保存采集任务
        taskRepository.save(task);
        
        // 发布领域事件
        eventPublisher.publish(new CollectTaskCreatedEvent(
            task.getId().getValue(),
            task.getName(),
            task.getSourceId(),
            task.getTargetId()
        ));
        
        // 返回DTO
        return CollectTaskDTOAssembler.toDTO(task);
    }
    
    @Override
    public TaskExecutionDTO startTask(String taskId) {
        // 获取采集任务
        CollectTask task = findTaskById(taskId);
        
        // 创建执行记录
        TaskExecution execution = task.startExecution(SecurityUtils.getCurrentUser().getUsername());
        
        // 保存执行记录
        executionRepository.save(execution);
        
        // 发布领域事件
        eventPublisher.publish(new TaskExecutionCreatedEvent(
            execution.getId().getValue(),
            task.getId().getValue()
        ));
        
        // 异步执行采集任务
        taskExecutor.execute(() -> {
            ExecutionResult result = collectEngine.execute(task, execution);
            
            // 更新执行状态
            task.completeExecution(
                execution.getId(),
                result.isSuccess() ? ExecutionStatus.COMPLETED : ExecutionStatus.FAILED,
                result
            );
            
            // 保存任务和执行结果
            taskRepository.save(task);
            
            // 发布领域事件
            eventPublisher.publish(new TaskExecutionCompletedEvent(
                execution.getId().getValue(),
                task.getId().getValue(),
                result.isSuccess() ? "COMPLETED" : "FAILED"
            ));
        });
        
        // 返回执行DTO
        return TaskExecutionDTOAssembler.toDTO(execution);
    }
    
    @Override
    public void stopTask(String taskId) {
        // 获取任务的活动执行
        List<TaskExecution> activeExecutions = executionRepository.findActiveByTaskId(taskId);
        
        for (TaskExecution execution : activeExecutions) {
            // 取消执行
            collectEngine.cancel(execution.getId());
            
            // 更新执行状态
            execution.updateStatus(ExecutionStatus.CANCELLED);
            
            // 保存执行记录
            executionRepository.save(execution);
            
            // 发布领域事件
            eventPublisher.publish(new TaskExecutionCancelledEvent(
                execution.getId().getValue(),
                taskId
            ));
        }
    }
    
    @Override
    public TaskExecutionDTO getExecutionStatus(String executionId) {
        // 从数据库查询执行记录
        TaskExecution execution = executionRepository.findById(TaskExecutionId.of(executionId))
            .orElseThrow(() -> new ExecutionNotFoundException(executionId));
        
        // 如果执行尚未完成，从引擎获取最新状态
        if (execution.getStatus() == ExecutionStatus.RUNNING) {
            ExecutionStatus currentStatus = collectEngine.getStatus(execution.getId());
            
            // 如果状态已变更，更新执行记录
            if (currentStatus != execution.getStatus()) {
                execution.updateStatus(currentStatus);
                executionRepository.save(execution);
            }
        }
        
        // 返回执行DTO
        return TaskExecutionDTOAssembler.toDTO(execution);
    }
    
    private CollectTask findTaskById(String taskId) {
        return taskRepository.findById(CollectTaskId.of(taskId))
            .orElseThrow(() -> new TaskNotFoundException(taskId));
    }
    
    private void validateDataSource(String dataSourceId) {
        if (!dataSourceRepository.existsById(DataSourceId.of(dataSourceId))) {
            throw new DataSourceNotFoundException(dataSourceId);
        }
    }
}
```

### platform-collect-connectors

**职责**：
- 提供各类数据源的连接适配器
- 实现不同协议和格式的数据读取
- 支持连接池和资源管理

**连接器接口**：

```java
/**
 * 数据源连接器接口
 */
public interface DataSourceConnector {
    /**
     * 连接数据源
     * @param config 连接配置
     * @return 连接结果
     */
    ConnectionResult connect(ConnectionConfig config);
    
    /**
     * 测试数据源连接
     * @param config 连接配置
     * @return 测试结果
     */
    ConnectionTestResult testConnection(ConnectionConfig config);
    
    /**
     * 从数据源读取数据
     * @param config 连接配置
     * @param query 查询条件
     * @return 数据读取结果
     */
    DataReadResult read(ConnectionConfig config, DataQuery query);
    
    /**
     * 获取数据源元数据
     * @param config 连接配置
     * @return 元数据信息
     */
    MetadataResult getMetadata(ConnectionConfig config);
    
    /**
     * 关闭连接
     */
    void disconnect();
    
    /**
     * 获取连接器类型
     * @return 连接器类型
     */
    DataSourceType getType();
}
```

**JDBC连接器实现**：

```java
/**
 * JDBC数据源连接器
 */
@Component
public class JdbcConnector implements DataSourceConnector {
    private static final Logger logger = LoggerFactory.getLogger(JdbcConnector.class);
    
    private DataSource dataSource;
    private ConnectionConfig currentConfig;
    
    @Override
    public ConnectionResult connect(ConnectionConfig config) {
        try {
            this.currentConfig = config;
            
            HikariConfig hikariConfig = new HikariConfig();
            hikariConfig.setJdbcUrl(config.getConnectionUrl());
            hikariConfig.setUsername(config.getUsername());
            hikariConfig.setPassword(config.getPassword());
            hikariConfig.setDriverClassName(config.getDriverClass());
            hikariConfig.setMaximumPoolSize(config.getMaxConnections());
            hikariConfig.setConnectionTimeout(config.getTimeoutSeconds() * 1000L);
            
            // 设置额外属性
            if (config.getConnectionProperties() != null) {
                Properties props = parseConnectionProperties(config.getConnectionProperties());
                props.forEach((key, value) -> hikariConfig.addDataSourceProperty(key.toString(), value));
            }
            
            this.dataSource = new HikariDataSource(hikariConfig);
            
            // 测试连接
            try (Connection conn = dataSource.getConnection()) {
                return new ConnectionResult(true, "Connected successfully");
            }
            
        } catch (Exception e) {
            logger.error("Failed to connect to JDBC data source", e);
            return new ConnectionResult(false, "Connection failed: " + e.getMessage());
        }
    }
    
    @Override
    public ConnectionTestResult testConnection(ConnectionConfig config) {
        try {
            // 创建临时连接池
            HikariConfig hikariConfig = new HikariConfig();
            hikariConfig.setJdbcUrl(config.getConnectionUrl());
            hikariConfig.setUsername(config.getUsername());
            hikariConfig.setPassword(config.getPassword());
            hikariConfig.setDriverClassName(config.getDriverClass());
            hikariConfig.setMaximumPoolSize(1);
            hikariConfig.setConnectionTimeout(config.getTimeoutSeconds() * 1000L);
            
            try (HikariDataSource ds = new HikariDataSource(hikariConfig);
                 Connection conn = ds.getConnection()) {
                
                // 测试数据库功能
                try (Statement stmt = conn.createStatement()) {
                    // 执行简单查询
                    try (ResultSet rs = stmt.executeQuery("SELECT 1")) {
                        if (rs.next()) {
                            return new ConnectionTestResult(true, "Connection test successful");
                        }
                    }
                }
            }
            
            return new ConnectionTestResult(false, "Connection test failed");
            
        } catch (Exception e) {
            logger.error("Connection test failed", e);
            return new ConnectionTestResult(false, "Connection test failed: " + e.getMessage());
        }
    }
    
    @Override
    public DataReadResult read(ConnectionConfig config, DataQuery query) {
        // 确保连接已建立
        if (dataSource == null || !config.equals(currentConfig)) {
            connect(config);
        }
        
        try (Connection conn = dataSource.getConnection()) {
            String sql = query.getSql();
            
            // 如果是增量查询，添加增量条件
            if (query.isIncremental() && query.getLastValue() != null) {
                sql = addIncrementalCondition(sql, query.getIncrementalField(), query.getLastValue());
            }
            
            try (PreparedStatement stmt = conn.prepareStatement(sql)) {
                // 设置查询参数
                if (query.getParameters() != null) {
                    for (int i = 0; i < query.getParameters().size(); i++) {
                        stmt.setObject(i + 1, query.getParameters().get(i));
                    }
                }
                
                // 设置批处理大小
                stmt.setFetchSize(query.getBatchSize());
                
                // 执行查询
                try (ResultSet rs = stmt.executeQuery()) {
                    List<DataRecord> records = new ArrayList<>();
                    ResultSetMetaData metaData = rs.getMetaData();
                    int columnCount = metaData.getColumnCount();
                    
                    // 解析结果集
                    while (rs.next()) {
                        DataRecord record = new DataRecord();
                        
                        for (int i = 1; i <= columnCount; i++) {
                            String columnName = metaData.getColumnLabel(i);
                            Object value = rs.getObject(i);
                            record.addField(columnName, value);
                        }
                        
                        records.add(record);
                    }
                    
                    return new DataReadResult(records, records.size());
                }
            }
            
        } catch (Exception e) {
            logger.error("Failed to read data from JDBC source", e);
            throw new DataReadException("Failed to read data: " + e.getMessage(), e);
        }
    }
    
    @Override
    public MetadataResult getMetadata(ConnectionConfig config) {
        try {
            // 确保连接已建立
            if (dataSource == null || !config.equals(currentConfig)) {
                connect(config);
            }
            
            try (Connection conn = dataSource.getConnection()) {
                DatabaseMetaData dbMetaData = conn.getMetaData();
                
                // 获取数据库信息
                DatabaseInfo dbInfo = new DatabaseInfo(
                    dbMetaData.getDatabaseProductName(),
                    dbMetaData.getDatabaseProductVersion(),
                    dbMetaData.getDatabaseMajorVersion(),
                    dbMetaData.getDatabaseMinorVersion()
                );
                
                // 获取表列表
                List<TableInfo> tables = new ArrayList<>();
                
                try (ResultSet rs = dbMetaData.getTables(
                        conn.getCatalog(), conn.getSchema(), "%", new String[]{"TABLE"})) {
                    
                    while (rs.next()) {
                        String tableName = rs.getString("TABLE_NAME");
                        String tableType = rs.getString("TABLE_TYPE");
                        
                        // 获取表字段
                        List<ColumnInfo> columns = new ArrayList<>();
                        
                        try (ResultSet columnRs = dbMetaData.getColumns(
                                conn.getCatalog(), conn.getSchema(), tableName, "%")) {
                            
                            while (columnRs.next()) {
                                String columnName = columnRs.getString("COLUMN_NAME");
                                int dataType = columnRs.getInt("DATA_TYPE");
                                String typeName = columnRs.getString("TYPE_NAME");
                                int columnSize = columnRs.getInt("COLUMN_SIZE");
                                boolean nullable = columnRs.getInt("NULLABLE") == DatabaseMetaData.columnNullable;
                                
                                columns.add(new ColumnInfo(
                                    columnName, 
                                    dataType, 
                                    typeName, 
                                    columnSize, 
                                    nullable
                                ));
                            }
                        }
                        
                        tables.add(new TableInfo(tableName, tableType, columns));
                    }
                }
                
                return new MetadataResult(dbInfo, tables);
            }
            
        } catch (Exception e) {
            logger.error("Failed to get metadata from JDBC source", e);
            throw new MetadataException("Failed to get metadata: " + e.getMessage(), e);
        }
    }
    
    @Override
    public void disconnect() {
        if (dataSource instanceof HikariDataSource) {
            ((HikariDataSource) dataSource).close();
        }
        dataSource = null;
        currentConfig = null;
    }
    
    @Override
    public DataSourceType getType() {
        return DataSourceType.JDBC;
    }
    
    private Properties parseConnectionProperties(String propertiesJson) {
        Properties props = new Properties();
        try {
            ObjectMapper mapper = new ObjectMapper();
            Map<String, String> map = mapper.readValue(propertiesJson, new TypeReference<Map<String, String>>() {});
            map.forEach(props::setProperty);
        } catch (Exception e) {
            logger.warn("Failed to parse connection properties JSON", e);
        }
        return props;
    }
    
    private String addIncrementalCondition(String sql, String incrementalField, Object lastValue) {
        // 简单实现，实际应用中需要更复杂的SQL解析
        String condition = "";
        
        if (lastValue instanceof Date) {
            condition = incrementalField + " > '" + new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format((Date) lastValue) + "'";
        } else if (lastValue instanceof Number) {
            condition = incrementalField + " > " + lastValue;
        } else {
            condition = incrementalField + " > '" + lastValue + "'";
        }
        
        if (sql.toLowerCase().contains("where")) {
            return sql + " AND " + condition;
        } else {
            return sql + " WHERE " + condition;
        }
    }
}
```

**连接器工厂**：

```java
/**
 * 连接器工厂
 */
@Component
public class DataSourceConnectorFactory {
    private final Map<DataSourceType, DataSourceConnector> connectors;
    
    public DataSourceConnectorFactory(List<DataSourceConnector> connectorList) {
        this.connectors = connectorList.stream()
            .collect(Collectors.toMap(DataSourceConnector::getType, Function.identity()));
    }
    
    public DataSourceConnector getConnector(DataSourceType type) {
        DataSourceConnector connector = connectors.get(type);
        if (connector == null) {
            throw new UnsupportedDataSourceTypeException("Unsupported data source type: " + type);
        }
        return connector;
    }
}
```

### platform-collect-processors

**职责**：
- 实现数据处理和转换逻辑
- 提供字段映射、类型转换等功能
- 支持数据验证和基本清洗

**处理器接口**：

```java
/**
 * 数据处理器接口
 */
public interface DataProcessor {
    /**
     * 处理数据记录
     * @param records 输入记录列表
     * @param params 处理器参数
     * @return 处理后的记录列表
     */
    List<DataRecord> process(List<DataRecord> records, Map<String, Object> params);
    
    /**
     * 获取处理器名称
     * @return 处理器名称
     */
    String getName();
}
```

**字段映射处理器**：

```java
/**
 * 字段映射处理器
 */
@Component
public class FieldMappingProcessor implements DataProcessor {
    private static final Logger logger = LoggerFactory.getLogger(FieldMappingProcessor.class);
    
    @Override
    public List<DataRecord> process(List<DataRecord> records, Map<String, Object> params) {
        // 获取字段映射配置
        Map<String, String> fieldMapping = getFieldMapping(params);
        
        if (fieldMapping.isEmpty()) {
            logger.warn("Field mapping is empty, skipping mapping");
            return records;
        }
        
        // 处理每条记录
        return records.stream()
            .map(record -> mapFields(record, fieldMapping))
            .collect(Collectors.toList());
    }
    
    @Override
    public String getName() {
        return "fieldMapping";
    }
    
    private Map<String, String> getFieldMapping(Map<String, Object> params) {
        if (params == null || !params.containsKey("fieldMapping")) {
            return Collections.emptyMap();
        }
        
        Object mappingObj = params.get("fieldMapping");
        
        if (mappingObj instanceof Map) {
            Map<?, ?> mappingMap = (Map<?, ?>) mappingObj;
            Map<String, String> mapping = new HashMap<>();
            
            mappingMap.forEach((k, v) -> {
                if (k != null && v != null) {
                    mapping.put(k.toString(), v.toString());
                }
            });
            
            return mapping;
        }
        
        return Collections.emptyMap();
    }
    
    private DataRecord mapFields(DataRecord record, Map<String, String> fieldMapping) {
        DataRecord result = new DataRecord();
        
        // 复制所有字段
        record.getFields().forEach(result::addField);
        
        // 应用字段映射
        fieldMapping.forEach((sourceField, targetField) -> {
            if (record.hasField(sourceField)) {
                Object value = record.getField(sourceField);
                result.addField(targetField, value);
                
                // 如果目标字段和源字段不同，移除源字段
                if (!sourceField.equals(targetField)) {
                    result.removeField(sourceField);
                }
            }
        });
        
        return result;
    }
}
```

**数据转换处理器**：

```java
/**
 * 数据类型转换处理器
 */
@Component
public class DataTypeConversionProcessor implements DataProcessor {
    private static final Logger logger = LoggerFactory.getLogger(DataTypeConversionProcessor.class);
    
    @Override
    public List<DataRecord> process(List<DataRecord> records, Map<String, Object> params) {
        // 获取类型转换配置
        Map<String, String> typeConversions = getTypeConversions(params);
        
        if (typeConversions.isEmpty()) {
            logger.warn("Type conversion map is empty, skipping conversion");
            return records;
        }
        
        // 处理每条记录
        return records.stream()
            .map(record -> convertTypes(record, typeConversions))
            .collect(Collectors.toList());
    }
    
    @Override
    public String getName() {
        return "dataTypeConversion";
    }
    
    private Map<String, String> getTypeConversions(Map<String, Object> params) {
        if (params == null || !params.containsKey("typeConversions")) {
            return Collections.emptyMap();
        }
        
        Object conversionsObj = params.get("typeConversions");
        
        if (conversionsObj instanceof Map) {
            Map<?, ?> conversionsMap = (Map<?, ?>) conversionsObj;
            Map<String, String> conversions = new HashMap<>();
            
            conversionsMap.forEach((k, v) -> {
                if (k != null && v != null) {
                    conversions.put(k.toString(), v.toString());
                }
            });
            
            return conversions;
        }
        
        return Collections.emptyMap();
    }
    
    private DataRecord convertTypes(DataRecord record, Map<String, String> typeConversions) {
        DataRecord result = new DataRecord();
        
        record.getFields().forEach((fieldName, value) -> {
            // 检查是否需要转换
            if (typeConversions.containsKey(fieldName)) {
                String targetType = typeConversions.get(fieldName);
                try {
                    Object convertedValue = convertValue(value, targetType);
                    result.addField(fieldName, convertedValue);
                } catch (Exception e) {
                    logger.warn("Failed to convert field '{}' to type '{}': {}", 
                        fieldName, targetType, e.getMessage());
                    result.addField(fieldName, value); // 保留原值
                }
            } else {
                result.addField(fieldName, value); // 保留原值
            }
        });
        
        return result;
    }
    
    private Object convertValue(Object value, String targetType) {
        if (value == null) {
            return null;
        }
        
        switch (targetType.toLowerCase()) {
            case "string":
                return value.toString();
                
            case "integer":
            case "int":
                if (value instanceof Number) {
                    return ((Number) value).intValue();
                } else {
                    return Integer.parseInt(value.toString().trim());
                }
                
            case "long":
                if (value instanceof Number) {
                    return ((Number) value).longValue();
                } else {
                    return Long.parseLong(value.toString().trim());
                }
                
            case "double":
            case "float":
                if (value instanceof Number) {
                    return ((Number) value).doubleValue();
                } else {
                    return Double.parseDouble(value.toString().trim());
                }
                
            case "boolean":
                if (value instanceof Boolean) {
                    return value;
                } else if (value instanceof Number) {
                    return ((Number) value).intValue() != 0;
                } else {
                    String strValue = value.toString().trim().toLowerCase();
                    return "true".equals(strValue) || "yes".equals(strValue) || "1".equals(strValue);
                }
                
            case "date":
                if (value instanceof Date) {
                    return value;
                } else {
                    // 尝试多种日期格式
                    String strValue = value.toString().trim();
                    try {
                        return new SimpleDateFormat("yyyy-MM-dd").parse(strValue);
                    } catch (Exception e1) {
                        try {
                            return new SimpleDateFormat("yyyy/MM/dd").parse(strValue);
                        } catch (Exception e2) {
                            return new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").parse(strValue);
                        }
                    }
                }
                
            case "timestamp":
                if (value instanceof Date) {
                    return new Timestamp(((Date) value).getTime());
                } else if (value instanceof Number) {
                    return new Timestamp(((Number) value).longValue());
                } else {
                    // 尝试解析为日期，然后转换为时间戳
                    String strValue = value.toString().trim();
                    try {
                        Date date = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").parse(strValue);
                        return new Timestamp(date.getTime());
                    } catch (Exception e) {
                        // 尝试其他格式...
                        throw new IllegalArgumentException("Cannot convert to timestamp: " + strValue);
                    }
                }
                
            default:
                throw new IllegalArgumentException("Unsupported target type: " + targetType);
        }
    }
}
```

### platform-collect-loaders

**职责**：
- 实现数据加载到目标存储
- 支持批量加载和事务控制
- 提供冲突处理和错误恢复机制

**加载器接口**：

```java
/**
 * 数据加载器接口
 */
public interface DataLoader {
    /**
     * 加载数据到目标存储
     * @param config 连接配置
     * @param records 数据记录列表
     * @param taskConfig 任务配置
     * @return 加载结果
     */
    DataLoadResult load(ConnectionConfig config, List<DataRecord> records, TaskConfig taskConfig);
    
    /**
     * 获取加载器支持的数据源类型
     * @return 数据源类型
     */
    DataSourceType getType();
}
```

**JDBC数据加载器**：

```java
/**
 * JDBC数据加载器
 */
@Component
public class JdbcDataLoader implements DataLoader {
    private static final Logger logger = LoggerFactory.getLogger(JdbcDataLoader.class);
    
    @Override
    public DataLoadResult load(ConnectionConfig config, List<DataRecord> records, TaskConfig taskConfig) {
        if (records.isEmpty()) {
            logger.info("No records to load");
            return new DataLoadResult(0, 0, Collections.emptyList());
        }
        
        int loadedRecords = 0;
        int errorRecords = 0;
        List<String> errorMessages = new ArrayList<>();
        
        try {
            // 创建连接池
            HikariConfig hikariConfig = new HikariConfig();
            hikariConfig.setJdbcUrl(config.getConnectionUrl());
            hikariConfig.setUsername(config.getUsername());
            hikariConfig.setPassword(config.getPassword());
            hikariConfig.setDriverClassName(config.getDriverClass());
            hikariConfig.setMaximumPoolSize(config.getMaxConnections());
            
            try (HikariDataSource dataSource = new HikariDataSource(hikariConfig);
                 Connection conn = dataSource.getConnection()) {
                
                // 获取目标表名
                String tableName = taskConfig.getTargetTable();
                if (tableName == null || tableName.isEmpty()) {
                    throw new IllegalArgumentException("Target table name is not specified");
                }
                
                // 获取写入模式
                String writeMode = taskConfig.getWriteMode();
                if (writeMode == null) {
                    writeMode = "insert"; // 默认为插入模式
                }
                
                // 获取批处理大小
                int batchSize = taskConfig.getBatchSize();
                if (batchSize <= 0) {
                    batchSize = 1000; // 默认批处理大小
                }
                
                // 根据写入模式执行不同的加载逻辑
                switch (writeMode.toLowerCase()) {
                    case "insert":
                        loadedRecords = insertRecords(conn, tableName, records, batchSize, errorMessages);
                        break;
                        
                    case "update":
                        loadedRecords = updateRecords(conn, tableName, records, taskConfig.getKeyFields(), 
                                                     batchSize, errorMessages);
                        break;
                        
                    case "upsert":
                        loadedRecords = upsertRecords(conn, tableName, records, taskConfig.getKeyFields(), 
                                                     batchSize, errorMessages);
                        break;
                        
                    default:
                        throw new IllegalArgumentException("Unsupported write mode: " + writeMode);
                }
                
                errorRecords = records.size() - loadedRecords;
                
            }
        } catch (Exception e) {
            logger.error("Failed to load data to JDBC target", e);
            errorRecords = records.size();
            errorMessages.add("Load failed: " + e.getMessage());
        }
        
        return new DataLoadResult(loadedRecords, errorRecords, errorMessages);
    }
    
    @Override
    public DataSourceType getType() {
        return DataSourceType.JDBC;
    }
    
    private int insertRecords(Connection conn, String tableName, List<DataRecord> records, 
                             int batchSize, List<String> errorMessages) throws SQLException {
        
        int loadedRecords = 0;
        
        // 检查记录列表是否为空
        if (records.isEmpty()) {
            return 0;
        }
        
        // 获取第一条记录的字段列表
        DataRecord firstRecord = records.get(0);
        List<String> fields = new ArrayList<>(firstRecord.getFields().keySet());
        
        // 构建插入SQL
        StringBuilder sql = new StringBuilder();
        sql.append("INSERT INTO ").append(tableName).append(" (");
        
        // 添加字段名
        sql.append(String.join(", ", fields));
        
        sql.append(") VALUES (");
        
        // 添加占位符
        sql.append(String.join(", ", Collections.nCopies(fields.size(), "?")));
        
        sql.append(")");
        
        // 设置连接为手动提交
        boolean autoCommit = conn.getAutoCommit();
        conn.setAutoCommit(false);
        
        try (PreparedStatement stmt = conn.prepareStatement(sql.toString())) {
            int batchCount = 0;
            
            for (DataRecord record : records) {
                // 设置参数值
                for (int i = 0; i < fields.size(); i++) {
                    stmt.setObject(i + 1, record.getField(fields.get(i)));
                }
                
                stmt.addBatch();
                batchCount++;
                
                // 达到批处理大小时执行
                if (batchCount >= batchSize) {
                    try {
                        int[] results = stmt.executeBatch();
                        loadedRecords += countSuccessfulUpdates(results);
                    } catch (BatchUpdateException e) {
                        int[] results = e.getUpdateCounts();
                        loadedRecords += countSuccessfulUpdates(results);
                        errorMessages.add("Batch insert partially failed: " + e.getMessage());
                        logger.warn("Batch insert partially failed", e);
                    }
                    
                    conn.commit();
                    batchCount = 0;
                }
            }
            
            // 处理剩余的批次
            if (batchCount > 0) {
                try {
                    int[] results = stmt.executeBatch();
                    loadedRecords += countSuccessfulUpdates(results);
                } catch (BatchUpdateException e) {
                    int[] results = e.getUpdateCounts();
                    loadedRecords += countSuccessfulUpdates(results);
                    errorMessages.add("Batch insert partially failed: " + e.getMessage());
                    logger.warn("Batch insert partially failed", e);
                }
                
                conn.commit();
            }
        } catch (SQLException e) {
            conn.rollback();
            throw e;
        } finally {
            conn.setAutoCommit(autoCommit);
        }
        
        return loadedRecords;
    }
    
    private int updateRecords(Connection conn, String tableName, List<DataRecord> records, 
                             List<String> keyFields, int batchSize, List<String> errorMessages) 
                             throws SQLException {
        
        // 验证关键字段
        if (keyFields == null || keyFields.isEmpty()) {
            throw new IllegalArgumentException("Key fields are required for update mode");
        }
        
        int loadedRecords = 0;
        
        // 检查记录列表是否为空
        if (records.isEmpty()) {
            return 0;
        }
        
        // 获取第一条记录的字段列表（除关键字段外）
        DataRecord firstRecord = records.get(0);
        List<String> updateFields = new ArrayList<>(firstRecord.getFields().keySet());
        updateFields.removeAll(keyFields);
        
        if (updateFields.isEmpty()) {
            throw new IllegalArgumentException("No fields to update");
        }
        
        // 构建更新SQL
        StringBuilder sql = new StringBuilder();
        sql.append("UPDATE ").append(tableName).append(" SET ");
        
        // 添加更新字段
        for (int i = 0; i < updateFields.size(); i++) {
            if (i > 0) {
                sql.append(", ");
            }
            sql.append(updateFields.get(i)).append(" = ?");
        }
        
        // 添加WHERE条件
        sql.append(" WHERE ");
        for (int i = 0; i < keyFields.size(); i++) {
            if (i > 0) {
                sql.append(" AND ");
            }
            sql.append(keyFields.get(i)).append(" = ?");
        }
        
        // 设置连接为手动提交
        boolean autoCommit = conn.getAutoCommit();
        conn.setAutoCommit(false);
        
        try (PreparedStatement stmt = conn.prepareStatement(sql.toString())) {
            int batchCount = 0;
            
            for (DataRecord record : records) {
                // 设置更新字段参数
                int paramIndex = 1;
                for (String field : updateFields) {
                    stmt.setObject(paramIndex++, record.getField(field));
                }
                
                // 设置关键字段参数
                for (String keyField : keyFields) {
                    Object keyValue = record.getField(keyField);
                    if (keyValue == null) {
                        throw new IllegalArgumentException("Key field '" + keyField + "' cannot be null");
                    }
                    stmt.setObject(paramIndex++, keyValue);
                }
                
                stmt.addBatch();
                batchCount++;
                
                // 达到批处理大小时执行
                if (batchCount >= batchSize) {
                    try {
                        int[] results = stmt.executeBatch();
                        loadedRecords += countSuccessfulUpdates(results);
                    } catch (BatchUpdateException e) {
                        int[] results = e.getUpdateCounts();
                        loadedRecords += countSuccessfulUpdates(results);
                        errorMessages.add("Batch update partially failed: " + e.getMessage());
                        logger.warn("Batch update partially failed", e);
                    }
                    
                    conn.commit();
                    batchCount = 0;
                }
            }
            
            // 处理剩余的批次
            if (batchCount > 0) {
                try {
                    int[] results = stmt.executeBatch();
                    loadedRecords += countSuccessfulUpdates(results);
                } catch (BatchUpdateException e) {
                    int[] results = e.getUpdateCounts();
                    loadedRecords += countSuccessfulUpdates(results);
                    errorMessages.add("Batch update partially failed: " + e.getMessage());
                    logger.warn("Batch update partially failed", e);
                }
                
                conn.commit();
            }
        } catch (SQLException e) {
            conn.rollback();
            throw e;
        } finally {
            conn.setAutoCommit(autoCommit);
        }
        
        return loadedRecords;
    }
    
    private int upsertRecords(Connection conn, String tableName, List<DataRecord> records, 
                             List<String> keyFields, int batchSize, List<String> errorMessages) 
                             throws SQLException {
        
        // 具体实现取决于数据库类型，这里提供MySQL的实现
        String dbType = getDatabaseType(conn);
        
        switch (dbType.toLowerCase()) {
            case "mysql":
                return mysqlUpsert(conn, tableName, records, keyFields, batchSize, errorMessages);
                
            case "postgresql":
                return postgresUpsert(conn, tableName, records, keyFields, batchSize, errorMessages);
                
            default:
                // 回退到普通的插入更新逻辑
                logger.warn("Unsupported database type for native upsert: {}", dbType);
                return fallbackUpsert(conn, tableName, records, keyFields, batchSize, errorMessages);
        }
    }
    
    private String getDatabaseType(Connection conn) throws SQLException {
        return conn.getMetaData().getDatabaseProductName();
    }
    
    private int mysqlUpsert(Connection conn, String tableName, List<DataRecord> records, 
                           List<String> keyFields, int batchSize, List<String> errorMessages) 
                           throws SQLException {
        
        int loadedRecords = 0;
        
        // 检查记录列表是否为空
        if (records.isEmpty()) {
            return 0;
        }
        
        // 获取第一条记录的字段列表
        DataRecord firstRecord = records.get(0);
        List<String> fields = new ArrayList<>(firstRecord.getFields().keySet());
        
        // 构建upsert SQL (INSERT ... ON DUPLICATE KEY UPDATE)
        StringBuilder sql = new StringBuilder();
        sql.append("INSERT INTO ").append(tableName).append(" (");
        
        // 添加字段名
        sql.append(String.join(", ", fields));
        
        sql.append(") VALUES (");
        
        // 添加占位符
        sql.append(String.join(", ", Collections.nCopies(fields.size(), "?")));
        
        sql.append(") ON DUPLICATE KEY UPDATE ");
        
        // 添加更新语句
        List<String> updateClauses = new ArrayList<>();
        for (String field : fields) {
            if (!keyFields.contains(field)) {
                updateClauses.add(field + " = VALUES(" + field + ")");
            }
        }
        
        sql.append(String.join(", ", updateClauses));
        
        // 设置连接为手动提交
        boolean autoCommit = conn.getAutoCommit();
        conn.setAutoCommit(false);
        
        try (PreparedStatement stmt = conn.prepareStatement(sql.toString())) {
            int batchCount = 0;
            
            for (DataRecord record : records) {
                // 设置参数值
                for (int i = 0; i < fields.size(); i++) {
                    stmt.setObject(i + 1, record.getField(fields.get(i)));
                }
                
                stmt.addBatch();
                batchCount++;
                
                // 达到批处理大小时执行
                if (batchCount >= batchSize) {
                    try {
                        int[] results = stmt.executeBatch();
                        loadedRecords += countSuccessfulUpserts(results);
                    } catch (BatchUpdateException e) {
                        int[] results = e.getUpdateCounts();
                        loadedRecords += countSuccessfulUpserts(results);
                        errorMessages.add("Batch upsert partially failed: " + e.getMessage());
                        logger.warn("Batch upsert partially failed", e);
                    }
                    
                    conn.commit();
                    batchCount = 0;
                }
            }
            
            // 处理剩余的批次
            if (batchCount > 0) {
                try {
                    int[] results = stmt.executeBatch();
                    loadedRecords += countSuccessfulUpserts(results);
                } catch (BatchUpdateException e) {
                    int[] results = e.getUpdateCounts();
                    loadedRecords += countSuccessfulUpserts(results);
                    errorMessages.add("Batch upsert partially failed: " + e.getMessage());
                    logger.warn("Batch upsert partially failed", e);
                }
                
                conn.commit();
            }
        } catch (SQLException e) {
            conn.rollback();
            throw e;
        } finally {
            conn.setAutoCommit(autoCommit);
        }
        
        return loadedRecords;
    }
    
    private int postgresUpsert(Connection conn, String tableName, List<DataRecord> records, 
                              List<String> keyFields, int batchSize, List<String> errorMessages) 
                              throws SQLException {
        
        // 验证关键字段
        if (keyFields == null || keyFields.isEmpty()) {
            throw new IllegalArgumentException("Key fields are required for upsert mode");
        }
        
        int loadedRecords = 0;
        
        // 检查记录列表是否为空
        if (records.isEmpty()) {
            return 0;
        }
        
        // 获取第一条记录的字段列表
        DataRecord firstRecord = records.get(0);
        List<String> fields = new ArrayList<>(firstRecord.getFields().keySet());
        
        // 除关键字段外的更新字段
        List<String> updateFields = new ArrayList<>(fields);
        updateFields.removeAll(keyFields);
        
        // 构建upsert SQL (INSERT ... ON CONFLICT ... DO UPDATE)
        StringBuilder sql = new StringBuilder();
        sql.append("INSERT INTO ").append(tableName).append(" (");
        
        // 添加字段名
        sql.append(String.join(", ", fields));
        
        sql.append(") VALUES (");
        
        // 添加占位符
        sql.append(String.join(", ", Collections.nCopies(fields.size(), "?")));
        
        sql.append(") ON CONFLICT (");
        
        // 添加冲突字段
        sql.append(String.join(", ", keyFields));
        
        sql.append(") DO UPDATE SET ");
        
        // 添加更新语句
        List<String> updateClauses = new ArrayList<>();
        for (String field : updateFields) {
            updateClauses.add(field + " = EXCLUDED." + field);
        }
        
        sql.append(String.join(", ", updateClauses));
        
        // 设置连接为手动提交
        boolean autoCommit = conn.getAutoCommit();
        conn.setAutoCommit(false);
        
        try (PreparedStatement stmt = conn.prepareStatement(sql.toString())) {
            int batchCount = 0;
            
            for (DataRecord record : records) {
                // 设置参数值
                for (int i = 0; i < fields.size(); i++) {
                    stmt.setObject(i + 1, record.getField(fields.get(i)));
                }
                
                stmt.addBatch();
                batchCount++;
                
                // 达到批处理大小时执行
                if (batchCount >= batchSize) {
                    try {
                        int[] results = stmt.executeBatch();
                        loadedRecords += countSuccessfulUpserts(results);
                    } catch (BatchUpdateException e) {
                        int[] results = e.getUpdateCounts();
                        loadedRecords += countSuccessfulUpserts(results);
                        errorMessages.add("Batch upsert partially failed: " + e.getMessage());
                        logger.warn("Batch upsert partially failed", e);
                    }
                    
                    conn.commit();
                    batchCount = 0;
                }
            }
            
            // 处理剩余的批次
            if (batchCount > 0) {
                try {
                    int[] results = stmt.executeBatch();
                    loadedRecords += countSuccessfulUpserts(results);
                } catch (BatchUpdateException e) {
                    int[] results = e.getUpdateCounts();
                    loadedRecords += countSuccessfulUpserts(results);
                    errorMessages.add("Batch upsert partially failed: " + e.getMessage());
                    logger.warn("Batch upsert partially failed", e);
                }
                
                conn.commit();
            }
        } catch (SQLException e) {
            conn.rollback();
            throw e;
        } finally {
            conn.setAutoCommit(autoCommit);
        }
        
        return loadedRecords;
    }
    
    private int fallbackUpsert(Connection conn, String tableName, List<DataRecord> records, 
                              List<String> keyFields, int batchSize, List<String> errorMessages) 
                              throws SQLException {
        
        int loadedRecords = 0;
        
        // 逐条检查记录是否存在，然后选择插入或更新
        for (DataRecord record : records) {
            boolean exists = checkRecordExists(conn, tableName, record, keyFields);
            
            if (exists) {
                // 更新记录
                int updated = updateSingleRecord(conn, tableName, record, keyFields);
                loadedRecords += updated;
            } else {
                // 插入记录
                int inserted = insertSingleRecord(conn, tableName, record);
                loadedRecords += inserted;
            }
        }
        
        return loadedRecords;
    }
    
    private boolean checkRecordExists(Connection conn, String tableName, 
                                     DataRecord record, List<String> keyFields) 
                                     throws SQLException {
        
        StringBuilder sql = new StringBuilder();
        sql.append("SELECT 1 FROM ").append(tableName).append(" WHERE ");
        
        // 添加条件
        List<String> conditions = new ArrayList<>();
        for (String keyField : keyFields) {
            conditions.add(keyField + " = ?");
        }
        
        sql.append(String.join(" AND ", conditions));
        
        try (PreparedStatement stmt = conn.prepareStatement(sql.toString())) {
            // 设置参数
            for (int i = 0; i < keyFields.size(); i++) {
                stmt.setObject(i + 1, record.getField(keyFields.get(i)));
            }
            
            try (ResultSet rs = stmt.executeQuery()) {
                return rs.next();
            }
        }
    }
    
    private int updateSingleRecord(Connection conn, String tableName, 
                                  DataRecord record, List<String> keyFields) 
                                  throws SQLException {
        
        // 获取更新字段（非关键字段）
        List<String> updateFields = new ArrayList<>(record.getFields().keySet());
        updateFields.removeAll(keyFields);
        
        if (updateFields.isEmpty()) {
            return 0; // 没有需要更新的字段
        }
        
        StringBuilder sql = new StringBuilder();
        sql.append("UPDATE ").append(tableName).append(" SET ");
        
        // 添加更新字段
        List<String> updateClauses = new ArrayList<>();
        for (String field : updateFields) {
            updateClauses.add(field + " = ?");
        }
        
        sql.append(String.join(", ", updateClauses));
        
        // 添加条件
        sql.append(" WHERE ");
        List<String> conditions = new ArrayList<>();
        for (String keyField : keyFields) {
            conditions.add(keyField + " = ?");
        }
        
        sql.append(String.join(" AND ", conditions));
        
        try (PreparedStatement stmt = conn.prepareStatement(sql.toString())) {
            // 设置更新字段参数
            int paramIndex = 1;
            for (String field : updateFields) {
                stmt.setObject(paramIndex++, record.getField(field));
            }
            
            // 设置条件参数
            for (String keyField : keyFields) {
                stmt.setObject(paramIndex++, record.getField(keyField));
            }
            
            return stmt.executeUpdate();
        }
    }
    
    private int insertSingleRecord(Connection conn, String tableName, DataRecord record) 
                                  throws SQLException {
        
        List<String> fields = new ArrayList<>(record.getFields().keySet());
        
        StringBuilder sql = new StringBuilder();
        sql.append("INSERT INTO ").append(tableName).append(" (");
        
        // 添加字段名
        sql.append(String.join(", ", fields));
        
        sql.append(") VALUES (");
        
        // 添加占位符
        sql.append(String.join(", ", Collections.nCopies(fields.size(), "?")));
        
        sql.append(")");
        
        try (PreparedStatement stmt = conn.prepareStatement(sql.toString())) {
            // 设置参数
            for (int i = 0; i < fields.size(); i++) {
                stmt.setObject(i + 1, record.getField(fields.get(i)));
            }
            
            return stmt.executeUpdate();
        }
    }
    
    private int countSuccessfulUpdates(int[] results) {
        int count = 0;
        for (int result : results) {
            if (result != Statement.EXECUTE_FAILED) {
                count++;
            }
        }
        return count;
    }
    
    private int countSuccessfulUpserts(int[] results) {
        int count = 0;
        for (int result : results) {
            if (result != Statement.EXECUTE_FAILED) {
                count++;
            }
        }
        return count;
    }
}
```

### platform-collect-admin

**职责**：
- 提供数据采集任务的管理界面
- 支持任务配置、监控和结果查看
- 实现采集历史和日志查询

**控制器实现**：

```java
/**
 * 数据源控制器
 */
@RestController
@RequestMapping("/api/datasources")
public class DataSourceController {
    private final DataSourceApplicationService dataSourceService;
    
    public DataSourceController(DataSourceApplicationService dataSourceService) {
        this.dataSourceService = dataSourceService;
    }
    
    @PostMapping
    @PreAuthorize("hasAuthority('DATASOURCE_CREATE')")
    public ResponseEntity<DataSourceDTO> createDataSource(@RequestBody @Valid CreateDataSourceRequest request) {
        CreateDataSourceCommand command = CreateDataSourceCommand.builder()
            .name(request.getName())
            .description(request.getDescription())
            .type(request.getType())
            .connectionConfig(request.getConnectionConfig())
            .createdBy(SecurityUtils.getCurrentUsername())
            .build();
        
        DataSourceDTO dataSource = dataSourceService.createDataSource(command);
        
        return ResponseEntity
            .created(URI.create("/api/datasources/" + dataSource.getId()))
            .body(dataSource);
    }
    
    @GetMapping("/{id}")
    @PreAuthorize("hasAuthority('DATASOURCE_READ')")
    public ResponseEntity<DataSourceDTO> getDataSource(@PathVariable String id) {
        DataSourceDTO dataSource = dataSourceService.getDataSourceById(id);
        return ResponseEntity.ok(dataSource);
    }
    
    @GetMapping
    @PreAuthorize("hasAuthority('DATASOURCE_READ')")
    public ResponseEntity<Page<DataSourceDTO>> getDataSources(
            @RequestParam(defaultValue = "0") int page,
            @RequestParam(defaultValue = "20") int size,
            @RequestParam(required = false) String name,
            @RequestParam(required = false) DataSourceType type) {
        
        GetDataSourcesQuery query = GetDataSourcesQuery.builder()
            .page(page)
            .size(size)
            .name(name)
            .type(type)
            .build();
        
        Page<DataSourceDTO> dataSources = dataSourceService.getDataSources(query);
        
        return ResponseEntity.ok(dataSources);
    }
    
    @PutMapping("/{id}")
    @PreAuthorize("hasAuthority('DATASOURCE_UPDATE')")
    public ResponseEntity<DataSourceDTO> updateDataSource(
            @PathVariable String id,
            @RequestBody @Valid UpdateDataSourceRequest request) {
        
        UpdateDataSourceCommand command = UpdateDataSourceCommand.builder()
            .id(id)
            .name(request.getName())
            .description(request.getDescription())
            .connectionConfig(request.getConnectionConfig())
            .updatedBy(SecurityUtils.getCurrentUsername())
            .build();
        
        DataSourceDTO dataSource = dataSourceService.updateDataSource(command);
        
        return ResponseEntity.ok(dataSource);
    }
    
    @DeleteMapping("/{id}")
    @PreAuthorize("hasAuthority('DATASOURCE_DELETE')")
    public ResponseEntity<Void> deleteDataSource(@PathVariable String id) {
        dataSourceService.deleteDataSource(id, SecurityUtils.getCurrentUsername());
        return ResponseEntity.noContent().build();
    }
    
    @PostMapping("/{id}/test-connection")
    @PreAuthorize("hasAuthority('DATASOURCE_READ')")
    public ResponseEntity<ConnectionTestResultDTO> testConnection(@PathVariable String id) {
        ConnectionTestResultDTO result = dataSourceService.testConnection(id);
        return ResponseEntity.ok(result);
    }
    
    @GetMapping("/{id}/metadata")
    @PreAuthorize("hasAuthority('DATASOURCE_READ')")
    public ResponseEntity<MetadataResultDTO> getMetadata(@PathVariable String id) {
        MetadataResultDTO result = dataSourceService.getMetadata(id);
        return ResponseEntity.ok(result);
    }
}

/**
 * 采集任务控制器
 */
@RestController
@RequestMapping("/api/collect-tasks")
public class CollectTaskController {
    private final CollectTaskApplicationService taskService;
    
    public CollectTaskController(CollectTaskApplicationService taskService) {
        this.taskService = taskService;
    }
    
    @PostMapping
    @PreAuthorize("hasAuthority('TASK_CREATE')")
    public ResponseEntity<CollectTaskDTO> createCollectTask(@RequestBody @Valid CreateCollectTaskRequest request) {
        CreateCollectTaskCommand command = CreateCollectTaskCommand.builder()
            .name(request.getName())
            .description(request.getDescription())
            .sourceId(request.getSourceId())
            .targetId(request.getTargetId())
            .taskConfig(request.getTaskConfig())
            .taskSchedule(request.getTaskSchedule())
            .createdBy(SecurityUtils.getCurrentUsername())
            .build();
        
        CollectTaskDTO task = taskService.createCollectTask(command);
        
        return ResponseEntity
            .created(URI.create("/api/collect-tasks/" + task.getId()))
            .body(task);
    }
    
    @GetMapping("/{id}")
    @PreAuthorize("hasAuthority('TASK_READ')")
    public ResponseEntity<CollectTaskDTO> getCollectTask(@PathVariable String id) {
        CollectTaskDTO task = taskService.getCollectTaskById(id);
        return ResponseEntity.ok(task);
    }
    
    @GetMapping
    @PreAuthorize("hasAuthority('TASK_READ')")
    public ResponseEntity<Page<CollectTaskDTO>> getCollectTasks(
            @RequestParam(defaultValue = "0") int page,
            @RequestParam(defaultValue = "20") int size,
            @RequestParam(required = false) String name,
            @RequestParam(required = false) String sourceId,
            @RequestParam(required = false) TaskStatus status) {
        
        GetCollectTasksQuery query = GetCollectTasksQuery.builder()
            .page(page)
            .size(size)
            .name(name)
            .sourceId(sourceId)
            .status(status)
            .build();
        
        Page<CollectTaskDTO> tasks = taskService.getCollectTasks(query);
        
        return ResponseEntity.ok(tasks);
    }
    
    @PutMapping("/{id}")
    @PreAuthorize("hasAuthority('TASK_UPDATE')")
    public ResponseEntity<CollectTaskDTO> updateCollectTask(
            @PathVariable String id,
            @RequestBody @Valid UpdateCollectTaskRequest request) {
        
        UpdateCollectTaskCommand command = UpdateCollectTaskCommand.builder()
            .id(id)
            .name(request.getName())
            .description(request.getDescription())
            .taskConfig(request.getTaskConfig())
            .taskSchedule(request.getTaskSchedule())
            .updatedBy(SecurityUtils.getCurrentUsername())
            .build();
        
        CollectTaskDTO task = taskService.updateCollectTask(command);
        
        return ResponseEntity.ok(task);
    }
    
    @DeleteMapping("/{id}")
    @PreAuthorize("hasAuthority('TASK_DELETE')")
    public ResponseEntity<Void> deleteCollectTask(@PathVariable String id) {
        taskService.deleteCollectTask(id, SecurityUtils.getCurrentUsername());
        return ResponseEntity.noContent().build();
    }
    
    @PostMapping("/{id}/activate")
    @PreAuthorize("hasAuthority('TASK_EXECUTE')")
    public ResponseEntity<CollectTaskDTO> activateTask(@PathVariable String id) {
        CollectTaskDTO task = taskService.activateTask(id, SecurityUtils.getCurrentUsername());
        return ResponseEntity.ok(task);
    }
    
    @PostMapping("/{id}/deactivate")
    @PreAuthorize("hasAuthority('TASK_EXECUTE')")
    public ResponseEntity<CollectTaskDTO> deactivateTask(@PathVariable String id) {
        CollectTaskDTO task = taskService.deactivateTask(id, SecurityUtils.getCurrentUsername());
        return ResponseEntity.ok(task);
    }
    
    @PostMapping("/{id}/execute")
    @PreAuthorize("hasAuthority('TASK_EXECUTE')")
    public ResponseEntity<TaskExecutionDTO> executeTask(@PathVariable String id) {
        TaskExecutionDTO execution = taskService.startTask(id);
        return ResponseEntity.accepted().body(execution);
    }
    
    @PostMapping("/{id}/stop")
    @PreAuthorize("hasAuthority('TASK_EXECUTE')")
    public ResponseEntity<Void> stopTask(@PathVariable String id) {
        taskService.stopTask(id);
        return ResponseEntity.accepted().build();
    }
    
    @GetMapping("/{id}/executions")
    @PreAuthorize("hasAuthority('TASK_READ')")
    public ResponseEntity<Page<TaskExecutionDTO>> getTaskExecutions(
            @PathVariable String id,
            @RequestParam(defaultValue = "0") int page,
            @RequestParam(defaultValue = "20") int size) {
        
        GetTaskExecutionsQuery query = GetTaskExecutionsQuery.builder()
            .taskId(id)
            .page(page)
            .size(size)
            .build();
        
        Page<TaskExecutionDTO> executions = taskService.getTaskExecutions(query);
        
        return ResponseEntity.ok(executions);
    }
    
    @GetMapping("/executions/{executionId}")
    @PreAuthorize("hasAuthority('TASK_READ')")
    public ResponseEntity<TaskExecutionDTO> getTaskExecution(@PathVariable String executionId) {
        TaskExecutionDTO execution = taskService.getExecutionStatus(executionId);
        return ResponseEntity.ok(execution);
    }
}
```

## 配置范例

```yaml
spring:
  application:
    name: platform-collect
  datasource:
    url: jdbc:mysql://${MYSQL_HOST:localhost}:${MYSQL_PORT:3306}/${MYSQL_DATABASE:collect_db}?useSSL=false&serverTimezone=UTC
    username: ${MYSQL_USERNAME:root}
    password: ${MYSQL_PASSWORD:password}
    driver-class-name: com.mysql.cj.jdbc.Driver
  jpa:
    hibernate:
      ddl-auto: validate
    properties:
      hibernate:
        dialect: org.hibernate.dialect.MySQL8Dialect
    open-in-view: false

# 数据采集配置
collect:
  max-concurrent-tasks: 10
  task-timeout-minutes: 60
  batch-size: 1000
  retry:
    max-attempts: 3
    initial-interval-seconds: 5
    multiplier: 2.0
  connectors:
    jdbc:
      enabled: true
      default-driver-class: com.mysql.cj.jdbc.Driver
      connection-pool-size: 10
    file:
      enabled: true
      supported-formats: csv,json,xml,excel
      temp-dir: ${java.io.tmpdir}/collect
    api:
      enabled: true
      timeout-seconds: 30
      max-retries: 3
    kafka:
      enabled: true
      bootstrap-servers: ${KAFKA_SERVERS:localhost:9092}
    mongodb:
      enabled: true

server:
  port: 8081

management:
  endpoints:
    web:
      exposure:
        include: '*'
  endpoint:
    health:
      show-details: ALWAYS
```